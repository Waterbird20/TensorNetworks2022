{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Machine learning with MPS\n",
"Author: <https://cqm.snu.ac.kr Seung-Sup Lee>\n",
"\n",
"Here we demonstrate how the MPS technology can be used in machine learning, \n",
"with the application to handwriting recognition. We implement the algorithm \n",
"introduced in Stoudenmire2016 [<https://proceedings.neurips.cc/paper/2016/file/5314b9674c86e3f9d1ba25ef9bb32895-Paper.pdf \n",
"E. M. Stoudenmire and D. J. Schwab, Adv. Neural Inf. Process. Syst. *29*, 4799 \n",
"(2016)> or <https://arxiv.org/abs/1605.05775 its arXiv version>]. (Two versions \n",
"of the paper have minor differences; here we follow the notation of the published \n",
"NeurIPS version.) The goal of this algorithm is to construct the MPS such that \n",
"the contraction of the \"weight\" MPS and feature vectors evaluates how the input \n",
"data is close to the data pattern with a certain label.\n",
"## MNIST data\n",
"First, we load the MNIST data of handwritten digits, from the .csv files contained \n",
"in the same sub-directory with this document. In these .csv files, each row \n",
"corresponds one handwritten digit. The first column indicates the correct labels. \n",
"The rest of columns, of column indices **(1:(28^2))+1**, indicate the gray-scale \n",
"values (from black 0 to white 255) of 28 $\\times$ 28 image pixels. For each \n",
"row, the **(2:(28^2+1))** elements are the concatenation of rows of an image, \n",
"i.e., **[(the_1st_row), (the_2nd_row), ...]**.\n",
"\n",
"For quicker demonstration, we use only a subset for training (i.e., optimizing \n",
"the MPS) and a smaller subset for test the performance of the trained MPS. (To \n",
"have better classification result, one needs to use the whole dataset; but it \n",
"will take more computational cost.)\n",
"```Matlab\n",
"clear\n",
"\n",
"Ntrain = 2000; % number of training datasets\n",
"Ntest = 100; % number of test datasets for verification\n",
"Npixel = 28; % number of pixels of an image for each direction\n",
"\n",
"data_train = readmatrix('MNIST_train.csv','Range',[1 1 Ntrain 28^2+1]);\n",
"data_test  = readmatrix('MNIST_test.csv', 'Range',[1 1 Ntest  28^2+1]);\n",
"```\n",
"The numbers are from 0 to 9.\n",
"```Matlab\n",
"labels = unique(data_train(:,1));\n",
"disp(labels.');\n",
"```\n",
"Let's visualize the data.\n",
"```Matlab\n",
"Nshow = [5 5]; % 5-by-5 layout\n",
"figure;\n",
"imagesc(reshape(permute(reshape(data_train(1:prod(Nshow),2:end), ...\n",
"    [Nshow Npixel Npixel]),[4 1 3 2]),Nshow*Npixel));\n",
"permute the dimensions of column/row of pixels for visualization, since\n",
"MATLAB is column-major language\n",
"colormap(gray);\n",
"title('Training data (original)','FontSize',14);\n",
"```\n",
"These gray-scale images are labeled as:\n",
"```Matlab\n",
"disp(reshape(data_train(1:prod(Nshow),1),Nshow))\n",
"```\n",
"In Stoudenmire2016, the images are down-scaled by factor 2. By down-scaling, \n",
"we later can use shorter MPS of length $(28/2)^2 = 196$.\n",
"```Matlab\n",
"data_train = [data_train(:,1), ...\n",
"    reshape(mean(mean( ...\n",
"    reshape(data_train(:,(2:end)),[size(data_train,1) 2 Npixel/2 2 Npixel/2]), ...\n",
"    2),4),[size(data_train,1) (Npixel/2)^2])];\n",
"data_test = [data_test(:,1), ...\n",
"    reshape(mean(mean( ...\n",
"    reshape(data_test(:,(2:end)),[size(data_test,1) 2 Npixel/2 2 Npixel/2]), ...\n",
"    2),4),[size(data_test,1) (Npixel/2)^2])];\n",
"```\n",
"The down-scaled images look like:\n",
"```Matlab\n",
"figure;\n",
"imagesc(reshape(permute(reshape(data_train(1:prod(Nshow),2:end), ...\n",
"    [Nshow Npixel/2 Npixel/2]),[4 1 3 2]),Nshow*Npixel/2));\n",
"permute the dimensions of column/row of pixels for visualization, since\n",
"MATLAB is column-major language\n",
"colormap(gray);\n",
"title('Training data (down-scaled)','FontSize',14);\n",
"## Generate feature vectors and correct decision function\n",
"Then the gray-scale pixels are individually mapped onto two-dimensional vectors \n",
"which are similar to the spin-1/2 spinors. In the machine learning context, \n",
"we will call such vectors as feature vectors.\n",
"\n",
"We define the mapping from an integer $\\in [0, 255]$ to a two-dimensional \n",
"vector so that for completely white pixels, the vector would be [0 1] and for \n",
"completely black pixels, [1 0]. We use Eq. (3) of Stoudenmire2016, which provides \n",
"the one-to-one correspondence between a pixel value and a vector.\n",
"\n",
"dtmp = data_train(:,2:end)*(pi/2/255);\n",
"F_train = permute(cat(3,cos(dtmp),sin(dtmp)),[1 3 2]);\n",
"F_train(m,:,n) is the 2-dimensional feature vector for the n-th pixel (=\n",
"site) and the m-th image\n",
"\n",
"% similarly for test data\n",
"dtmp = data_test(:,2:end)*(pi/2/255);\n",
"F_test = permute(cat(3,cos(dtmp),sin(dtmp)),[1 3 2]);\n",
"```\n",
"And we also construct the matrix for correct decision function.\n",
"```Matlab\n",
"% for training data\n",
"y_train = accumarray([(1:size(data_train,1)).', data_train(:,1)+1], ...\n",
"    ones(size(data_train,1),1),[size(data_train,1) numel(labels)]);\n",
"y_train(m,n) is 1 if the m-th data (i.e. image) is labeled by the n-th \n",
"label, 0 otherwise.\n",
"\n",
"% similarly for test data\n",
"y_test = accumarray([(1:size(data_test,1)).', data_test(:,1)+1], ...\n",
"    ones(size(data_test,1),1),[size(data_test,1) numel(labels)]);\n",
"## Exercise (a): Complete the function for the MPS-based machine learning method\n",
"Here now we arrive at the last exercise in this lecture course (_Hurray!_). \n",
"There is a function **ML_MPS_Ex.m** contained in the same sub-directory with this \n",
"script. The provided file is incomplete. Complete the parts enclosed by the \n",
"comments **TODO (start)** and **TODO (end)**, following the description given in \n",
"Sec. 4 of Stoudenmire2016. Once you complete the function, you can follow the \n",
"demonstration below.\n",
"\n",
"Note that there are some important technical details that are not discussed \n",
"in Stoudenmire2016 and devised by Seung-Sup Lee to achieve stability and performance. \n",
"Such parts in the code are denoted by the comment \"[Unpublished; devised by \n",
"S.Lee]\".\n",
"## Machine learning of recognizing handwritten digits\n",
"The prefactor $\\eta$ to the gradient $\\Delta B$ [see the first sentence of \n",
"the paragraph containing Eq. (8) in Stoudenmire2016] is a parameter which can \n",
"affect the convergence of the algorithm. Since the gradient descent is used \n",
"to update tensors, we need to choose the value of $\\eta$ carefully. We use smaller \n",
"$\\eta$'s for earlier sweeps (where the gradients have larger magnitude since \n",
"the tensors are far from the optimized; if $\\eta$'s are large there, then it \n",
"might be overshooting) and larger $\\eta$'s for later sweeps (where the gradients \n",
"have smaller magnitude; if $\\eta$'s are small there, then the tensors will not \n",
"change that much). Note that the choice of $\\eta$ values may depend on other \n",
"parameters such as **Ntrain**, **Nkeep**, etc.\n",
"\n",
"Nkeep = 20;\n",
"estep = [0.1 0.3 1 3 10 12 14];\n",
"[M,cfun,err,lid,cfun_test,err_test,lid_test] = ...\n",
"    ML_MPS_Ex ([],F_train,y_train,F_test,y_test,Nkeep,estep);\n",
"```\n",
"Plot how the cost function per dataset and the error rate of predicting correct \n",
"labels change.\n",
"```Matlab\n",
"figure;\n",
"plot((1:numel(cfun)).'/numel(M), ...\n",
"    [cfun(:),cfun_test(:),err(:),err_test(:)], ...\n",
"    'LineWidth',1,'LineStyle','-');\n",
"set(gca,'LineWidth',1,'FontSize',13,'YScale','linear');\n",
"legend({'Cost function (training)','Cost function (test)', ...\n",
"    'Error rate (training)','Error rate (test)'},'Location','best');\n",
"xlabel('# of sweeps')\n",
"grid on;\n",
"```\n",
"We get a classification error rate of 3%, comparable with the reported value \n",
"of 2% for the bond dimension $N_\\mathrm{keep} = 20$ (see Sec. 5 of Stoudenmire2016). \n",
"The classification error rate can be further improved by tuning **estep**, increasing \n",
"**Nkeep**, or training more datasets.\n",
"\n",
"Let's see some example for which the final MPS fails to classify data correctly.\n",
"```Matlab\n",
"ids = find((lid_test-1) ~= data_test(:,1));\n",
"for itf = ids(:).'\n",
"    figure;\n",
"    imagesc(reshape(data_test(itf,2:end),(Npixel/2)*[1 1]).');\n",
"    colormap(gray);\n",
"    title(['Exact = ',sprintf('%i',data_test(itf,1)), ...\n",
"        ', ML-MPS prediction = ',sprintf('%i',lid_test(itf)-1)]);\n",
"end\n",
"```\n",
"You see that the ML-MPS code was not entirely wrong, as it found \"similar\" \n",
"numbers in terms of their shapes!"

   ]
  }
 ],
 "metadata": {
	"language_info": {
	 "name": "python"
	},
	"orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}